{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rent the Runway: Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ariellemiro/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data cleaning\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "#Modeling \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Warnings - to keep the notebook clean \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns= 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bust_size</th>\n",
       "      <th>fit</th>\n",
       "      <th>height</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review_text</th>\n",
       "      <th>size</th>\n",
       "      <th>user_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_type_apple</th>\n",
       "      <th>body_type_athletic</th>\n",
       "      <th>body_type_full_bust</th>\n",
       "      <th>body_type_hourglass</th>\n",
       "      <th>body_type_pear</th>\n",
       "      <th>body_type_petite</th>\n",
       "      <th>body_type_straight_narrow</th>\n",
       "      <th>rented_for_date</th>\n",
       "      <th>rented_for_everyday</th>\n",
       "      <th>rented_for_formal_affair</th>\n",
       "      <th>rented_for_other</th>\n",
       "      <th>rented_for_party</th>\n",
       "      <th>rented_for_vacation</th>\n",
       "      <th>rented_for_wedding</th>\n",
       "      <th>rented_for_work</th>\n",
       "      <th>category_blazer</th>\n",
       "      <th>category_blouse</th>\n",
       "      <th>category_bomber</th>\n",
       "      <th>category_cami</th>\n",
       "      <th>category_cape</th>\n",
       "      <th>category_cardigan</th>\n",
       "      <th>category_coat</th>\n",
       "      <th>category_crewneck</th>\n",
       "      <th>category_culottes</th>\n",
       "      <th>category_down</th>\n",
       "      <th>category_dress</th>\n",
       "      <th>category_duster</th>\n",
       "      <th>category_frock</th>\n",
       "      <th>category_gown</th>\n",
       "      <th>category_henley</th>\n",
       "      <th>category_hoodie</th>\n",
       "      <th>category_jacket</th>\n",
       "      <th>category_jogger</th>\n",
       "      <th>category_jumpsuit</th>\n",
       "      <th>category_kaftan</th>\n",
       "      <th>category_kimono</th>\n",
       "      <th>category_knit</th>\n",
       "      <th>category_leggings</th>\n",
       "      <th>category_maxi</th>\n",
       "      <th>category_midi</th>\n",
       "      <th>category_mini</th>\n",
       "      <th>category_overalls</th>\n",
       "      <th>category_pants</th>\n",
       "      <th>category_parka</th>\n",
       "      <th>category_peacoat</th>\n",
       "      <th>category_poncho</th>\n",
       "      <th>category_print</th>\n",
       "      <th>category_pullover</th>\n",
       "      <th>category_romper</th>\n",
       "      <th>category_sheath</th>\n",
       "      <th>category_shift</th>\n",
       "      <th>category_shirt</th>\n",
       "      <th>category_shirtdress</th>\n",
       "      <th>category_skirt</th>\n",
       "      <th>category_suit</th>\n",
       "      <th>category_sweater</th>\n",
       "      <th>category_sweatpants</th>\n",
       "      <th>category_sweatshirt</th>\n",
       "      <th>category_tank</th>\n",
       "      <th>category_tee</th>\n",
       "      <th>category_tight</th>\n",
       "      <th>category_top</th>\n",
       "      <th>category_trench</th>\n",
       "      <th>category_trousers</th>\n",
       "      <th>category_tunic</th>\n",
       "      <th>category_turtleneck</th>\n",
       "      <th>category_vest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>34c</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>937638</td>\n",
       "      <td>8</td>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>Colorful, unique dress for a formal event</td>\n",
       "      <td>I'm glad I got the backup size of 10 because i...</td>\n",
       "      <td>20</td>\n",
       "      <td>402340</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>32b</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>604383</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>Stylist Review</td>\n",
       "      <td>You can't help but feel powerful in this numbe...</td>\n",
       "      <td>24</td>\n",
       "      <td>380920</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>32a</td>\n",
       "      <td>2</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1505709</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>Easy to Wear, not much fuss</td>\n",
       "      <td>This runs big but it is still nice.  The mater...</td>\n",
       "      <td>4</td>\n",
       "      <td>234255</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>34a</td>\n",
       "      <td>1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>127495</td>\n",
       "      <td>10</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>Rented for my best friends bachelorette party....</td>\n",
       "      <td>The dress was perfect for fall/ winter weather...</td>\n",
       "      <td>4</td>\n",
       "      <td>763040</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>38d</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1001785</td>\n",
       "      <td>10</td>\n",
       "      <td>2015-09-30</td>\n",
       "      <td>This dress was perfect for Diner en Blanc. It ...</td>\n",
       "      <td>It was a tad bit snug around the arms, but I h...</td>\n",
       "      <td>32</td>\n",
       "      <td>698342</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age bust_size  fit  height  item_id  rating review_date  \\\n",
       "0   25       34c    0    65.0   937638       8  2017-01-29   \n",
       "1   26       32b    1    66.0   604383      10  2016-10-27   \n",
       "2   38       32a    2    63.0  1505709      10  2017-05-22   \n",
       "3   29       34a    1    61.0   127495      10  2014-11-05   \n",
       "4   35       38d    1    65.0  1001785      10  2015-09-30   \n",
       "\n",
       "                                      review_summary  \\\n",
       "0          Colorful, unique dress for a formal event   \n",
       "1                                    Stylist Review    \n",
       "2                        Easy to Wear, not much fuss   \n",
       "3  Rented for my best friends bachelorette party....   \n",
       "4  This dress was perfect for Diner en Blanc. It ...   \n",
       "\n",
       "                                         review_text  size  user_id  weight  \\\n",
       "0  I'm glad I got the backup size of 10 because i...    20   402340     145   \n",
       "1  You can't help but feel powerful in this numbe...    24   380920     160   \n",
       "2  This runs big but it is still nice.  The mater...     4   234255     108   \n",
       "3  The dress was perfect for fall/ winter weather...     4   763040     110   \n",
       "4  It was a tad bit snug around the arms, but I h...    32   698342     220   \n",
       "\n",
       "   body_type_apple  body_type_athletic  body_type_full_bust  \\\n",
       "0                0                   0                    0   \n",
       "1                0                   0                    0   \n",
       "2                0                   0                    0   \n",
       "3                0                   1                    0   \n",
       "4                0                   0                    1   \n",
       "\n",
       "   body_type_hourglass  body_type_pear  body_type_petite  \\\n",
       "0                    0               1                 0   \n",
       "1                    1               0                 0   \n",
       "2                    0               0                 0   \n",
       "3                    0               0                 0   \n",
       "4                    0               0                 0   \n",
       "\n",
       "   body_type_straight_narrow  rented_for_date  rented_for_everyday  \\\n",
       "0                          0                0                    0   \n",
       "1                          0                0                    0   \n",
       "2                          1                0                    0   \n",
       "3                          0                0                    0   \n",
       "4                          0                0                    0   \n",
       "\n",
       "   rented_for_formal_affair  rented_for_other  rented_for_party  \\\n",
       "0                         1                 0                 0   \n",
       "1                         1                 0                 0   \n",
       "2                         0                 0                 0   \n",
       "3                         0                 0                 1   \n",
       "4                         0                 1                 0   \n",
       "\n",
       "   rented_for_vacation  rented_for_wedding  rented_for_work  category_blazer  \\\n",
       "0                    0                   0                0                0   \n",
       "1                    0                   0                0                0   \n",
       "2                    0                   0                1                0   \n",
       "3                    0                   0                0                0   \n",
       "4                    0                   0                0                0   \n",
       "\n",
       "   category_blouse  category_bomber  category_cami  category_cape  \\\n",
       "0                0                0              0              0   \n",
       "1                0                0              0              0   \n",
       "2                0                0              0              0   \n",
       "3                0                0              0              0   \n",
       "4                0                0              0              0   \n",
       "\n",
       "   category_cardigan  category_coat  category_crewneck  category_culottes  \\\n",
       "0                  0              0                  0                  0   \n",
       "1                  0              0                  0                  0   \n",
       "2                  0              0                  0                  0   \n",
       "3                  0              0                  0                  0   \n",
       "4                  0              0                  0                  0   \n",
       "\n",
       "   category_down  category_dress  category_duster  category_frock  \\\n",
       "0              0               0                0               0   \n",
       "1              0               0                0               0   \n",
       "2              0               1                0               0   \n",
       "3              0               1                0               0   \n",
       "4              0               1                0               0   \n",
       "\n",
       "   category_gown  category_henley  category_hoodie  category_jacket  \\\n",
       "0              1                0                0                0   \n",
       "1              1                0                0                0   \n",
       "2              0                0                0                0   \n",
       "3              0                0                0                0   \n",
       "4              0                0                0                0   \n",
       "\n",
       "   category_jogger  category_jumpsuit  category_kaftan  category_kimono  \\\n",
       "0                0                  0                0                0   \n",
       "1                0                  0                0                0   \n",
       "2                0                  0                0                0   \n",
       "3                0                  0                0                0   \n",
       "4                0                  0                0                0   \n",
       "\n",
       "   category_knit  category_leggings  category_maxi  category_midi  \\\n",
       "0              0                  0              0              0   \n",
       "1              0                  0              0              0   \n",
       "2              0                  0              0              0   \n",
       "3              0                  0              0              0   \n",
       "4              0                  0              0              0   \n",
       "\n",
       "   category_mini  category_overalls  category_pants  category_parka  \\\n",
       "0              0                  0               0               0   \n",
       "1              0                  0               0               0   \n",
       "2              0                  0               0               0   \n",
       "3              0                  0               0               0   \n",
       "4              0                  0               0               0   \n",
       "\n",
       "   category_peacoat  category_poncho  category_print  category_pullover  \\\n",
       "0                 0                0               0                  0   \n",
       "1                 0                0               0                  0   \n",
       "2                 0                0               0                  0   \n",
       "3                 0                0               0                  0   \n",
       "4                 0                0               0                  0   \n",
       "\n",
       "   category_romper  category_sheath  category_shift  category_shirt  \\\n",
       "0                0                0               0               0   \n",
       "1                0                0               0               0   \n",
       "2                0                0               0               0   \n",
       "3                0                0               0               0   \n",
       "4                0                0               0               0   \n",
       "\n",
       "   category_shirtdress  category_skirt  category_suit  category_sweater  \\\n",
       "0                    0               0              0                 0   \n",
       "1                    0               0              0                 0   \n",
       "2                    0               0              0                 0   \n",
       "3                    0               0              0                 0   \n",
       "4                    0               0              0                 0   \n",
       "\n",
       "   category_sweatpants  category_sweatshirt  category_tank  category_tee  \\\n",
       "0                    0                    0              0             0   \n",
       "1                    0                    0              0             0   \n",
       "2                    0                    0              0             0   \n",
       "3                    0                    0              0             0   \n",
       "4                    0                    0              0             0   \n",
       "\n",
       "   category_tight  category_top  category_trench  category_trousers  \\\n",
       "0               0             0                0                  0   \n",
       "1               0             0                0                  0   \n",
       "2               0             0                0                  0   \n",
       "3               0             0                0                  0   \n",
       "4               0             0                0                  0   \n",
       "\n",
       "   category_tunic  category_turtleneck  category_vest  \n",
       "0               0                    0              0  \n",
       "1               0                    0              0  \n",
       "2               0                    0              0  \n",
       "3               0                    0              0  \n",
       "4               0                    0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the cleaned dataframe from the firt notebook \n",
    "df = pd.read_csv('./rent_the_runway_cleaned_with_dummies.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre- Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Gather all numeric columns excluding fit \n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).drop(columns= 'fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X & Y \n",
    "X = numeric_cols\n",
    "y = df['fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state =42, \n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.734124\n",
       "0    0.136681\n",
       "2    0.129195\n",
       "Name: fit, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the baseline \n",
    "# We can see that we also have unbalanced classes \n",
    "\n",
    "y.value_counts(normalize = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run different model types\n",
    "\n",
    "def fit_model(X, y, model_name='lr', model_type=LogisticRegression()):\n",
    "    \n",
    "    # Pipeline for pre-processing\n",
    "    pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        (model_name, model_type)\n",
    "    ])\n",
    "    # Fit the model \n",
    "    model = pipe.fit(X, y)\n",
    "    \n",
    "    #Score\n",
    "    score = model.score(X, y)\n",
    "                   \n",
    "    # Print attributes\n",
    "    print(f\"For model: {model_type}\")\n",
    "#     print(f\"Score: {score}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    # Evaluate training data\n",
    "    preds_train = model.predict(X_train)\n",
    "    score_train = model.score(X_train, y_train)\n",
    "\n",
    "    # Evaluate testing data\n",
    "    preds_test = model.predict(X_test)\n",
    "    score_test = model.score(X_test, y_test)\n",
    "    \n",
    "    # Print results\n",
    "    \n",
    "    print(f'Train Score: {score_train:.4f}')\n",
    "    print(f'Test Score: {score_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Train Score: 0.7368\n",
      "Test Score: 0.7344\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# Score very similar to the baseline, not overfit  \n",
    "logreg = fit_model(X_train, y_train, model_name='logreg', model_type=LogisticRegression())\n",
    "\n",
    "evaluate_model(logreg, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')\n",
      "Train Score: 0.7656\n",
      "Test Score: 0.6939\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# Score below baseline and overfit  \n",
    "knn = fit_model(X_train, y_train, model_name='knn', model_type=KNeighborsClassifier())\n",
    "\n",
    "evaluate_model(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Train Score: 0.9814\n",
      "Test Score: 0.7079\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "# Very overfit \n",
    "rf = fit_model(X_train, y_train, model_name='rf', model_type=RandomForestClassifier())\n",
    "\n",
    "evaluate_model(rf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
      "                   n_estimators=50, random_state=None)\n",
      "Train Score: 0.7369\n",
      "Test Score: 0.7349\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "# Similar score to baseline, not overfit  \n",
    "ada = fit_model(X_train, y_train, model_name='ada', model_type=AdaBoostClassifier())\n",
    "\n",
    "evaluate_model(ada, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: BaggingClassifier(base_estimator=None, bootstrap=True, bootstrap_features=False,\n",
      "                  max_features=1.0, max_samples=1.0, n_estimators=10,\n",
      "                  n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
      "                  warm_start=False)\n",
      "Train Score: 0.9819\n",
      "Test Score: 0.7033\n"
     ]
    }
   ],
   "source": [
    "# Bagging Classifier\n",
    "# Very overfit \n",
    "bag = fit_model(X_train, y_train, model_name='bag', model_type=BaggingClassifier())\n",
    "\n",
    "evaluate_model(bag, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)\n",
      "Train Score: 0.7363\n",
      "Test Score: 0.7341\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "# Similar to baseline\n",
    "svm = fit_model(X_train, y_train, model_name='svm', model_type=svm.SVC())\n",
    "\n",
    "evaluate_model(svm, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch through Best Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, Random Forests train score was strongl. I will gridsearch to improve the test score and minimize the overfitness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the Data (standard scaler was previously in the pipeline)\n",
    "ss = StandardScaler()                       \n",
    "ss.fit(X_train)                            \n",
    "X_train_sc = ss.transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7344483434352641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 10,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 750,\n",
       " 'n_jobs': -2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Indicate the gridearch params \n",
    "rf_params = {'bootstrap': [True], \n",
    "             'max_depth': [10], \n",
    "             'max_features':['auto'], \n",
    "             'min_samples_leaf': [1], \n",
    "             'min_samples_split': [10],\n",
    "             'n_estimators': [750] , \n",
    "             'n_jobs':[-2]}\n",
    "\n",
    "gs = GridSearchCV(rf, param_grid=rf_params, cv=5)\n",
    "gs.fit(X_train_sc, y_train)\n",
    "print(gs.best_score_)        \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7348129243950234\n",
      "0.7339712918660287\n",
      "0.7127558623437595\n"
     ]
    }
   ],
   "source": [
    "print(gs.score(X_train_sc, y_train))\n",
    "print(gs.score(X_test_sc, y_test))\n",
    "print(cross_val_score(rf, X_train_sc, y_train, cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to use smote here because the classes were unbalanced. Only the random forests performed well so I'm curious if smote will help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from kaggle\n",
    "# https://www.kaggle.com/qianchao/smote-with-imbalance-data\n",
    "\n",
    "#Gradient boosting\n",
    "#https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '2': 2835\n",
      "Before OverSampling, counts of label '1': 16109\n",
      "Before OverSampling, counts of label '0': 2999 \n",
      "\n",
      "After OverSampling, the shape of train_X: (48327, 74)\n",
      "After OverSampling, the shape of train_y: (48327,) \n",
      "\n",
      "After OverSampling, counts of label '2': 16109\n",
      "After OverSampling, counts of label '1': 16109\n",
      "After OverSampling, counts of label '0': 16109\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '2': {}\".format(sum(y_train==2)))\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '2': {}\".format(sum(y_train_res==2)))\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-fit on Gradient Boost Model to see if it improves the score** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n",
      "Train Score: 0.7440\n",
      "Test Score: 0.7289\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "# Accuracy for GB is not that strong - need to explore AUC ROC\n",
    "\n",
    "gb = fit_model(X_train_res, y_train_res, model_name='gb', model_type= GradientBoostingClassifier())\n",
    "\n",
    "evaluate_model(gb, X_train_res, X_test, y_train_res, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions \n",
    "preds_gb = gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the classes were unbalanced, I want to use AUC ROC score rather than accuracy. However there is no Multiclass AUC ROC score. I found this medium article: \n",
    "https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC ROC score for multiclass classification\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.548574374292707"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_roc_auc_score(y_test, preds_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1983, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7537</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27324</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25527</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9556</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       predicted  actual\n",
       "7537           1       2\n",
       "1140           1       2\n",
       "27324          1       2\n",
       "25527          0       2\n",
       "9556           1       2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with column for predicted values\n",
    "results = pd.DataFrame({'predicted': preds_gb, \n",
    "                        'actual': y_test})\n",
    "\n",
    "#Find the rows with incorrect predictions \n",
    "misclass = results[results['predicted'] != results['actual']]\n",
    "print(misclass.shape)\n",
    "misclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 133,  826,   41],\n",
       "       [ 161, 5101,  108],\n",
       "       [  39,  808,   98]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, \n",
    "                 preds_gb) \n",
    "\n",
    "#Here we can see the misclassified predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch through GradientBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenting out the below because my computer can't handle the gridsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7372738458733993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2,\n",
       " 'max_depth': 3,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 1.0,\n",
       " 'n_estimators': 300,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "#Indicate the gridearch params \n",
    "gb_params = {'learning_rate': [0.2],\n",
    "             'max_depth': [3], \n",
    "             'max_features' : ['auto'],\n",
    "             'min_samples_leaf': [3],\n",
    "             'min_samples_split': [1.0], \n",
    "             'n_estimators': [300],\n",
    "             'random_state' : [42]}\n",
    "\n",
    "gs = GridSearchCV(gb, param_grid=gb_params, cv=5)\n",
    "gs.fit(X_train_sc, y_train)\n",
    "print(gs.best_score_)        \n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7382764435127376\n",
      "0.7360218728639781\n",
      "0.7127558623437595\n"
     ]
    }
   ],
   "source": [
    "print(gs.score(X_train_sc, y_train))\n",
    "print(gs.score(X_test_sc, y_test))\n",
    "print(cross_val_score(rf, X_train_sc, y_train, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSI",
   "language": "python",
   "name": "dsi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
