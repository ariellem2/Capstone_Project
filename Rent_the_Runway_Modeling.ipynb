{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rent the Runway: Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "#Modeling \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#Warnings - to keep the notebook clean \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns= 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bust_size</th>\n",
       "      <th>fit</th>\n",
       "      <th>height</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>review_text</th>\n",
       "      <th>size</th>\n",
       "      <th>user_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>body_type_apple</th>\n",
       "      <th>body_type_athletic</th>\n",
       "      <th>body_type_full bust</th>\n",
       "      <th>body_type_hourglass</th>\n",
       "      <th>body_type_pear</th>\n",
       "      <th>body_type_petite</th>\n",
       "      <th>body_type_straight &amp; narrow</th>\n",
       "      <th>rented_for_date</th>\n",
       "      <th>rented_for_everyday</th>\n",
       "      <th>rented_for_formal affair</th>\n",
       "      <th>rented_for_other</th>\n",
       "      <th>rented_for_party</th>\n",
       "      <th>rented_for_vacation</th>\n",
       "      <th>rented_for_wedding</th>\n",
       "      <th>rented_for_work</th>\n",
       "      <th>category_ballgown</th>\n",
       "      <th>category_blazer</th>\n",
       "      <th>category_blouse</th>\n",
       "      <th>category_blouson</th>\n",
       "      <th>category_bomber</th>\n",
       "      <th>category_caftan</th>\n",
       "      <th>category_cami</th>\n",
       "      <th>category_cape</th>\n",
       "      <th>category_cardigan</th>\n",
       "      <th>category_coat</th>\n",
       "      <th>category_combo</th>\n",
       "      <th>category_culotte</th>\n",
       "      <th>category_culottes</th>\n",
       "      <th>category_down</th>\n",
       "      <th>category_dress</th>\n",
       "      <th>category_duster</th>\n",
       "      <th>category_frock</th>\n",
       "      <th>category_gown</th>\n",
       "      <th>category_henley</th>\n",
       "      <th>category_hoodie</th>\n",
       "      <th>category_jacket</th>\n",
       "      <th>category_jeans</th>\n",
       "      <th>category_jumpsuit</th>\n",
       "      <th>category_kaftan</th>\n",
       "      <th>category_kimono</th>\n",
       "      <th>category_knit</th>\n",
       "      <th>category_legging</th>\n",
       "      <th>category_leggings</th>\n",
       "      <th>category_maxi</th>\n",
       "      <th>category_midi</th>\n",
       "      <th>category_mini</th>\n",
       "      <th>category_overalls</th>\n",
       "      <th>category_pant</th>\n",
       "      <th>category_pants</th>\n",
       "      <th>category_parka</th>\n",
       "      <th>category_peacoat</th>\n",
       "      <th>category_poncho</th>\n",
       "      <th>category_print</th>\n",
       "      <th>category_pullover</th>\n",
       "      <th>category_romper</th>\n",
       "      <th>category_sheath</th>\n",
       "      <th>category_shift</th>\n",
       "      <th>category_shirt</th>\n",
       "      <th>category_shirtdress</th>\n",
       "      <th>category_skirt</th>\n",
       "      <th>category_skirts</th>\n",
       "      <th>category_skort</th>\n",
       "      <th>category_suit</th>\n",
       "      <th>category_sweater</th>\n",
       "      <th>category_sweatershirt</th>\n",
       "      <th>category_sweatshirt</th>\n",
       "      <th>category_t-shirt</th>\n",
       "      <th>category_tank</th>\n",
       "      <th>category_tee</th>\n",
       "      <th>category_tight</th>\n",
       "      <th>category_top</th>\n",
       "      <th>category_trench</th>\n",
       "      <th>category_trouser</th>\n",
       "      <th>category_trousers</th>\n",
       "      <th>category_tunic</th>\n",
       "      <th>category_turtleneck</th>\n",
       "      <th>category_vest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>34d</td>\n",
       "      <td>1</td>\n",
       "      <td>5. 5</td>\n",
       "      <td>815826</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-09-18</td>\n",
       "      <td>Good fit, great style, comfortable yet elegant</td>\n",
       "      <td>Rented for early brunch/garden wedding.  My to...</td>\n",
       "      <td>20</td>\n",
       "      <td>334577</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>34c</td>\n",
       "      <td>1</td>\n",
       "      <td>5. 5</td>\n",
       "      <td>1636171</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-04-19</td>\n",
       "      <td>Love the fit and fabric!</td>\n",
       "      <td>This dress was perfect. The fabric is thick an...</td>\n",
       "      <td>8</td>\n",
       "      <td>634115</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>34a</td>\n",
       "      <td>0</td>\n",
       "      <td>5. 8</td>\n",
       "      <td>438881</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-10-18</td>\n",
       "      <td>Simple black dress, loved the ruffles.</td>\n",
       "      <td>Wore this dress to a Naval Ball. The dress did...</td>\n",
       "      <td>13</td>\n",
       "      <td>988705</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>34d</td>\n",
       "      <td>1</td>\n",
       "      <td>5. 8</td>\n",
       "      <td>1392841</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>One of my fav rentals</td>\n",
       "      <td>Loved this fun dress. The low V in the front m...</td>\n",
       "      <td>16</td>\n",
       "      <td>977884</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>34a</td>\n",
       "      <td>2</td>\n",
       "      <td>5. 7</td>\n",
       "      <td>160612</td>\n",
       "      <td>8</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>Pretty but not meant for small chested girls</td>\n",
       "      <td>Pretty dress, but I didn't have the bust to fi...</td>\n",
       "      <td>8</td>\n",
       "      <td>795673</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age bust_size  fit height  item_id  rating review_date  \\\n",
       "0   36       34d    1  5. 5    815826      10  2017-09-18   \n",
       "1   34       34c    1  5. 5   1636171      10  2017-04-19   \n",
       "2   30       34a    0  5. 8    438881      10  2017-10-18   \n",
       "3   32       34d    1  5. 8   1392841      10  2017-08-07   \n",
       "4   34       34a    2  5. 7    160612       8  2015-01-05   \n",
       "\n",
       "                                   review_summary  \\\n",
       "0  Good fit, great style, comfortable yet elegant   \n",
       "1                       Love the fit and fabric!    \n",
       "2          Simple black dress, loved the ruffles.   \n",
       "3                           One of my fav rentals   \n",
       "4    Pretty but not meant for small chested girls   \n",
       "\n",
       "                                         review_text  size  user_id  weight  \\\n",
       "0  Rented for early brunch/garden wedding.  My to...    20   334577     137   \n",
       "1  This dress was perfect. The fabric is thick an...     8   634115     125   \n",
       "2  Wore this dress to a Naval Ball. The dress did...    13   988705     124   \n",
       "3  Loved this fun dress. The low V in the front m...    16   977884     158   \n",
       "4  Pretty dress, but I didn't have the bust to fi...     8   795673     135   \n",
       "\n",
       "   body_type_apple  body_type_athletic  body_type_full bust  \\\n",
       "0                0                   0                    0   \n",
       "1                0                   1                    0   \n",
       "2                0                   0                    0   \n",
       "3                0                   0                    0   \n",
       "4                0                   0                    0   \n",
       "\n",
       "   body_type_hourglass  body_type_pear  body_type_petite  \\\n",
       "0                    1               0                 0   \n",
       "1                    0               0                 0   \n",
       "2                    1               0                 0   \n",
       "3                    1               0                 0   \n",
       "4                    0               1                 0   \n",
       "\n",
       "   body_type_straight & narrow  rented_for_date  rented_for_everyday  \\\n",
       "0                            0                0                    0   \n",
       "1                            0                0                    0   \n",
       "2                            0                0                    0   \n",
       "3                            0                0                    0   \n",
       "4                            0                0                    0   \n",
       "\n",
       "   rented_for_formal affair  rented_for_other  rented_for_party  \\\n",
       "0                         0                 0                 0   \n",
       "1                         0                 0                 0   \n",
       "2                         1                 0                 0   \n",
       "3                         0                 0                 0   \n",
       "4                         0                 0                 1   \n",
       "\n",
       "   rented_for_vacation  rented_for_wedding  rented_for_work  \\\n",
       "0                    0                   1                0   \n",
       "1                    0                   0                1   \n",
       "2                    0                   0                0   \n",
       "3                    0                   1                0   \n",
       "4                    0                   0                0   \n",
       "\n",
       "   category_ballgown  category_blazer  category_blouse  category_blouson  \\\n",
       "0                  0                0                0                 0   \n",
       "1                  0                0                0                 0   \n",
       "2                  0                0                0                 0   \n",
       "3                  0                0                0                 0   \n",
       "4                  0                0                0                 0   \n",
       "\n",
       "   category_bomber  category_caftan  category_cami  category_cape  \\\n",
       "0                0                0              0              0   \n",
       "1                0                0              0              0   \n",
       "2                0                0              0              0   \n",
       "3                0                0              0              0   \n",
       "4                0                0              0              0   \n",
       "\n",
       "   category_cardigan  category_coat  category_combo  category_culotte  \\\n",
       "0                  0              0               0                 0   \n",
       "1                  0              0               0                 0   \n",
       "2                  0              0               0                 0   \n",
       "3                  0              0               0                 0   \n",
       "4                  0              0               0                 0   \n",
       "\n",
       "   category_culottes  category_down  category_dress  category_duster  \\\n",
       "0                  0              0               1                0   \n",
       "1                  0              0               1                0   \n",
       "2                  0              0               0                0   \n",
       "3                  0              0               1                0   \n",
       "4                  0              0               1                0   \n",
       "\n",
       "   category_frock  category_gown  category_henley  category_hoodie  \\\n",
       "0               0              0                0                0   \n",
       "1               0              0                0                0   \n",
       "2               0              1                0                0   \n",
       "3               0              0                0                0   \n",
       "4               0              0                0                0   \n",
       "\n",
       "   category_jacket  category_jeans  category_jumpsuit  category_kaftan  \\\n",
       "0                0               0                  0                0   \n",
       "1                0               0                  0                0   \n",
       "2                0               0                  0                0   \n",
       "3                0               0                  0                0   \n",
       "4                0               0                  0                0   \n",
       "\n",
       "   category_kimono  category_knit  category_legging  category_leggings  \\\n",
       "0                0              0                 0                  0   \n",
       "1                0              0                 0                  0   \n",
       "2                0              0                 0                  0   \n",
       "3                0              0                 0                  0   \n",
       "4                0              0                 0                  0   \n",
       "\n",
       "   category_maxi  category_midi  category_mini  category_overalls  \\\n",
       "0              0              0              0                  0   \n",
       "1              0              0              0                  0   \n",
       "2              0              0              0                  0   \n",
       "3              0              0              0                  0   \n",
       "4              0              0              0                  0   \n",
       "\n",
       "   category_pant  category_pants  category_parka  category_peacoat  \\\n",
       "0              0               0               0                 0   \n",
       "1              0               0               0                 0   \n",
       "2              0               0               0                 0   \n",
       "3              0               0               0                 0   \n",
       "4              0               0               0                 0   \n",
       "\n",
       "   category_poncho  category_print  category_pullover  category_romper  \\\n",
       "0                0               0                  0                0   \n",
       "1                0               0                  0                0   \n",
       "2                0               0                  0                0   \n",
       "3                0               0                  0                0   \n",
       "4                0               0                  0                0   \n",
       "\n",
       "   category_sheath  category_shift  category_shirt  category_shirtdress  \\\n",
       "0                0               0               0                    0   \n",
       "1                0               0               0                    0   \n",
       "2                0               0               0                    0   \n",
       "3                0               0               0                    0   \n",
       "4                0               0               0                    0   \n",
       "\n",
       "   category_skirt  category_skirts  category_skort  category_suit  \\\n",
       "0               0                0               0              0   \n",
       "1               0                0               0              0   \n",
       "2               0                0               0              0   \n",
       "3               0                0               0              0   \n",
       "4               0                0               0              0   \n",
       "\n",
       "   category_sweater  category_sweatershirt  category_sweatshirt  \\\n",
       "0                 0                      0                    0   \n",
       "1                 0                      0                    0   \n",
       "2                 0                      0                    0   \n",
       "3                 0                      0                    0   \n",
       "4                 0                      0                    0   \n",
       "\n",
       "   category_t-shirt  category_tank  category_tee  category_tight  \\\n",
       "0                 0              0             0               0   \n",
       "1                 0              0             0               0   \n",
       "2                 0              0             0               0   \n",
       "3                 0              0             0               0   \n",
       "4                 0              0             0               0   \n",
       "\n",
       "   category_top  category_trench  category_trouser  category_trousers  \\\n",
       "0             0                0                 0                  0   \n",
       "1             0                0                 0                  0   \n",
       "2             0                0                 0                  0   \n",
       "3             0                0                 0                  0   \n",
       "4             0                0                 0                  0   \n",
       "\n",
       "   category_tunic  category_turtleneck  category_vest  \n",
       "0               0                    0              0  \n",
       "1               0                    0              0  \n",
       "2               0                    0              0  \n",
       "3               0                    0              0  \n",
       "4               0                    0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./rent_the_runway_cleaned_with_dummies.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre- Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Gather all numeric columns excluding fit \n",
    "numeric_cols = df.select_dtypes(include=['int64']).drop(columns= 'fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X & Y \n",
    "X = numeric_cols\n",
    "y = df['fit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state =42, \n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.735927\n",
       "0    0.134513\n",
       "2    0.129560\n",
       "Name: fit, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the baseline \n",
    "# We can see that we also have unbalanced classes \n",
    "\n",
    "y.value_counts(normalize = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run different model types\n",
    "\n",
    "def fit_and_evaluate(X, y, model_name='lr', model_type=LogisticRegression()):\n",
    "    \n",
    "    # Pipeline for pre-processing\n",
    "    pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        (model_name, model_type)\n",
    "    ])\n",
    "    # Fit the model \n",
    "    model = pipe.fit(X, y)\n",
    "    \n",
    "    #Score\n",
    "    score = model.score(X, y)\n",
    "                   \n",
    "    # Print attributes\n",
    "    print(f\"For model: {model_type}\")\n",
    "    print(f\"Score: {score}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Score: 0.7376690804754747\n",
      "For model: LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Score: 0.7401284328460173\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# Score very similar to the baseline \n",
    "logreg = fit_and_evaluate(X_train, y_train, model_name='logreg', model_type=LogisticRegression())\n",
    "\n",
    "logreg = fit_and_evaluate(X_test, y_test, model_name='logreg', model_type=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.7650407614883636\n",
      "For model: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "Score: 0.7626724962426561\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "# Score slightly higher than the baseline \n",
    "knn = fit_and_evaluate(X_train, y_train, model_name='knn', model_type=KNeighborsClassifier())\n",
    "\n",
    "knn = fit_and_evaluate(X_test, y_test, model_name='knn', model_type=KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Score: 0.9816459443457667\n",
      "For model: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Score: 0.9816914879081842\n"
     ]
    }
   ],
   "source": [
    "# Random Forests\n",
    "# Good score!\n",
    "rf = fit_and_evaluate(X_train, y_train, model_name='rf', model_type=RandomForestClassifier())\n",
    "\n",
    "rf = fit_and_evaluate(X_test, y_test, model_name='rf', model_type=RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "Score: 0.7383066903493192\n",
      "For model: AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "Score: 0.7393086487225031\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "# Similar score to baseline \n",
    "ada = fit_and_evaluate(X_train, y_train, model_name='ada', model_type=AdaBoostClassifier())\n",
    "\n",
    "ada = fit_and_evaluate(X_test, y_test, model_name='ada', model_type=AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=None, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False)\n",
      "Score: 0.9808261602222526\n",
      "For model: BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=None, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False)\n",
      "Score: 0.9784123514141276\n"
     ]
    }
   ],
   "source": [
    "# Bagging Classifier\n",
    "# Good Scores! \n",
    "bag = fit_and_evaluate(X_train, y_train, model_name='bag', model_type=BaggingClassifier())\n",
    "\n",
    "bag = fit_and_evaluate(X_test, y_test, model_name='bag', model_type=BaggingClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch through Best Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, Random Forests did very well. I will gridsearch but there may be little room to improve the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the Data (standard scaler was previously in the pipeline)\n",
    "ss = StandardScaler()                       \n",
    "ss.fit(X_train)                            \n",
    "X_train_sc = ss.transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Random Forest\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# #Indicate the gridearch params \n",
    "# rf_params = {'bootstrap': [True, False], \n",
    "#              'max_depth': [10,25,50], \n",
    "#              'max_features':['auto'], \n",
    "#              'max_leaf_nodes':[ None],\n",
    "#              'min_impurity_split': [None],\n",
    "#              'min_samples_leaf': [1, 2, 4], \n",
    "#              'min_samples_split': [2, 5, 10],\n",
    "#              'n_estimators': [100, 300] , \n",
    "#              'n_jobs':[-2]}\n",
    "\n",
    "# gs = GridSearchCV(rf, param_grid=rf_params, cv=5)\n",
    "# gs.fit(X_train_sc, y_train)\n",
    "# print(gs.best_score_)        \n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(gs.score(X_train_sc, y_train))\n",
    "# print(gs.score(X_test_sc, y_test))\n",
    "# print(cross_val_score(rf, X_train_sc, y_train, cv=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to use smote here because the classes were unbalanced. Only the random forests performed well so I'm curious if smote will help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from kaggle\n",
    "# https://www.kaggle.com/qianchao/smote-with-imbalance-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '2': 2845\n",
      "Before OverSampling, counts of label '1': 16159\n",
      "Before OverSampling, counts of label '0': 2953 \n",
      "\n",
      "After OverSampling, the shape of train_X: (48477, 83)\n",
      "After OverSampling, the shape of train_y: (48477,) \n",
      "\n",
      "After OverSampling, counts of label '2': 16159\n",
      "After OverSampling, counts of label '1': 16159\n",
      "After OverSampling, counts of label '0': 16159\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '2': {}\".format(sum(y_train==2)))\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '2': {}\".format(sum(y_train_res==2)))\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balance the test data as well \n",
    "X_test_res, y_test_res = sm.fit_sample(X_test, y_test.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-fit on Gradient Boost Model to see if it improves the score** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "Score: 0.7181343730016296\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "# Accuracy for GB is not that strong - need to explore AUC ROC\n",
    "gb = fit_and_evaluate(X_train_res, y_train_res, model_name='gb', model_type= GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For model: GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              n_iter_no_change=None, presort='auto', random_state=None,\n",
      "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=0, warm_start=False)\n",
      "Score: 0.7414902834509222\n"
     ]
    }
   ],
   "source": [
    "gb = fit_and_evaluate(X_test_res, y_test_res, model_name='gb', model_type= GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions \n",
    "preds_gb = gb.predict(X_test_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the classes were unbalanced, I want to use AUC ROC score rather than accuracy. However there is not Multiclass AUC ROC score. I found this medium article: \n",
    "https://medium.com/@plog397/auc-roc-curve-scoring-function-for-multi-class-classification-9822871a6659"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC ROC score for multiclass classification\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061177125881915"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclass_roc_auc_score(y_test_res, preds_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smote helped to balance the classes, and the Gradient Boosting model has a decent AUC ROC score. However, the Random Forests model has a stronger accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch through GradientBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenting out the below because my computer can't handle the gridsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Gradient Boosting\n",
    "# gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# #Indicate the gridearch params \n",
    "# gb_params = {'learning_rate': [0.1],\n",
    "#              'max_depth': [3, 5], \n",
    "#              'min_samples_leaf': [1, 3],\n",
    "#              'min_samples_split': [2, 5], \n",
    "#              'n_estimators': [10, 50]}\n",
    "\n",
    "# gs = GridSearchCV(gb, param_grid=gb_params, cv=5)\n",
    "# gs.fit(X_train_sc, y_train)\n",
    "# print(gs.best_score_)        \n",
    "# gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, I have decided to move forward with the Random Forests model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate predictions for random forests\n",
    "preds_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9658995720238511"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the AUC ROC for Random Forests \n",
    "multiclass_roc_auc_score(y_test, preds_rf)\n",
    "\n",
    "#Even the AUC ROC score is good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(134, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24378</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27499</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25818</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23182</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       predicted  actual\n",
       "8978           1       0\n",
       "24378          1       2\n",
       "27499          1       2\n",
       "25818          1       2\n",
       "23182          1       2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with column for predicted values\n",
    "results = pd.DataFrame({'predicted': preds_rf, \n",
    "                        'actual': y_test})\n",
    "\n",
    "#Find the rows with incorrect predictions \n",
    "misclass = results[results['predicted'] != results['actual']]\n",
    "print(misclass.shape)\n",
    "misclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 943,   41,    1],\n",
       "       [   3, 5383,    0],\n",
       "       [   1,   88,  859]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, \n",
    "                 preds_rf) \n",
    "\n",
    "#Here we can see the misclassified predictions "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSI",
   "language": "python",
   "name": "dsi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
